""" Multioutput regression to predict 6 parameters for Taste/Thickness/Protien/etc (Thanks for suggestion)
"""

# https://machinelearningmastery.com/multi-output-regression-models-with-python/

from sklearn.neighbors import KNeighborsRegressor
from sklearn.tree import DecisionTreeRegressor
import pandas as pd 
import pickle
import pathlib

#df = pd.read_csv(str(pathlib.Path(__file__).parent / 'Proteinbar\Data\TF_Innov8_Protein_Bar_Modified_NS.csv'))
df = pd.read_csv(".\\Data\\TF_Innov8_Protein_Bar_Modified_NS.csv")

ingredient_columns = [
                      'I-003001_S-000102', 'I-003002_S-004001', 'I-003003_S-004002', 'I-003004_S-000102', 'I-003005_S-000102',
                      'I-003006_S-000102', 'I-003007_S-000102', 'I-003008_S-000102', 'I-003009_S-000102', 'I-003010_S-000102',
                      'I-003011_S-000102', 'I-003012_S-000102', 'I-003013_S-000102', 'I-003014_S-000102', 'I-003015_S-000102',
                      'I-003016_S-000102', 'I-003017_S-000102', 'I-003018_S-000102', 'I-003019_S-000102', 'I-003021_S-000102',
                      'I-003022_S-000102', 'I-003023_S-000102', 'I-003024_S-000102', 'I-003025_S-000102', 'I-003026_S-000102',
                      'I-003027_S-000102', 'I-003028_S-000102', 'I-003029_S-000102', 'I-003030_S-000102', 'I-003031_S-000102',
                      'I-003032_S-000102', 'I-003130_S-004003', 'I-003033_S-002001', 'I-003034_S-000102', 'I-003131_S-004007',
                      'I-003035_S-000102', 'I-003036_S-000102', 'I-003037_S-004004', 'I-003038_S-000102', 'I-003039_S-004005',
                      'I-003040_S-004006', 'I-003042_S-000102', 'I-003043_S-000102', 'I-003044_S-000102', 'I-003045_S-000102',
                      'I-003046_S-000102', 'I-003047_S-000102', 'I-003048_S-000102', 'I-003049_S-000102', 'I-003050_S-000102',
                      'I-003051_S-000102', 'I-003052_S-000102', 'I-003053_S-000102', 'I-003054_S-000102', 'I-003055_S-000102',
                      'I-003056_S-000102', 'I-003057_S-000102', 'I-003058_S-000102', 'I-001013_S-000102', 'I-003059_S-000102',
                      'I-003060_S-000102', 'I-003061_S-000102', 'I-003062_S-000102', 'I-003063_S-000102', 'I-003064_S-000102',
                      'I-003065_S-000102', 'I-003066_S-000102', 'I-003067_S-000102', 'I-003068_S-000102', 'I-003069_S-000102',
                      'I-003070_S-000102', 'I-003071_S-000102', 'I-003072_S-000102', 'I-003073_S-000102', 'I-003074_S-000102',
                      'I-003075_S-000102', 'I-003076_S-000102', 'I-003077_S-000102', 'I-003078_S-000102', 'I-003079_S-000102',
                      'I-003080_S-000102', 'I-003081_S-000102', 'I-003082_S-000102', 'I-003083_S-000102', 'I-003084_S-000102',
                      'I-003085_S-000102', 'I-003086_S-000102', 'I-003087_S-000102', 'I-003088_S-000102', 'I-003089_S-000102',
                      'I-003090_S-000102', 'I-003091_S-000102', 'I-003092_S-000102', 'I-003093_S-000102', 'I-003094_S-000102',
                      'I-003095_S-000102', 'I-003096_S-000102', 'I-003097_S-000102', 'I-003098_S-000102', 'I-003099_S-000102',
                      'I-003100_S-000102', 'I-003101_S-000102', 'I-003102_S-000102', 'I-003103_S-000102', 'I-003104_S-000102',
                      'I-003105_S-000102', 'I-003106_S-000102', 'I-003107_S-000102', 'I-003108_S-000102', 'I-003109_S-000102',
                      'I-003110_S-000102', 'I-003111_S-000102', 'I-003112_S-000102', 'I-003113_S-000102', 'I-003114_S-000102',
                      'I-003115_S-000102', 'I-003116_S-000102', 'I-001014_S-002011', 'I-003117_S-000102', 'I-003118_S-000102',
                      'I-003119_S-000102', 'I-003120_S-000102', 'I-000002_S-000102', 'I-003121_S-000102', 'I-003122_S-000102',
                      'I-003123_S-000102', 'I-003124_S-000102', 'I-003125_S-000102', 'I-003126_S-000102', 'I-003127_S-000102',
                      'I-003128_S-000102', 'I-003129_S-000102'
                      ]

X = df[ingredient_columns].values
y = df[["OP_000007", "OP_000012", "OP_000022", "OP_000023", "OP_000006", "OP_000024"]]

# define model

#model = LinearRegression()
model = DecisionTreeRegressor()
#model = KNeighborsRegressor()

# fit model
model.fit(X, y)

# save and load model
with open(str(pathlib.Path(__file__).parent/'parameter_classifier.pkl'), 'wb') as f:
    pickle.dump(model, f)

with open(str(pathlib.Path(__file__).parent/'parameter_classifier.pkl'), 'rb') as f:
    model = pickle.load(f)

# make a prediction with an example row from the dataset
#row = [11.30, 0, 0, 0, 60.08, 28.45, 0, 0.02, 0.01, 0, 0, 0, 0.02, 0, 0.13, 0]
row = [2,0,0,21,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0.3,0,0,0,0,0,0,0,0,1.5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,15,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.05,0,0,0,0,1,0,0,0,0,0,0,0,11,0,0,0,0,0,0,0,0,7,0,0,0,0,0,0,0,0,0,0,0.1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,21,0,0,0,0]
#row = [12, 0, 0, 0, 87.28, 0, 0, 0.03, 0.03, 0, 0, 0, 0.01, 0.05, 0.6, 0]
#row = [0, 12, 0, 0, 87.74, 0, 0, 0, 0, 0.15, 0, 0, 0.01, 0, 0.1, 0]
result = model.predict([row])[0]

# print prediction
print([f"{parameter_name} : {parameter}" for parameter, parameter_name in zip(result, ["OP_000007", "OP_000012", "OP_000022", "OP_000023", "OP_000006", "OP_000024"])])